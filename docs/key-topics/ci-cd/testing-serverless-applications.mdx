---
id: testing-serverless-applications
title: Developing Serverless Applications
sidebar_label: Developing Serverless Applications
keywords: ["webiny", "development", "unit", "e2e", "tests"]
description: Learn how to establish a CI/CD pipeline for your Webiny project.
---
:::tip What you'll learn
- what does it mean to develop serverless
- two
:::

## Overview

Serverless application development is different than "traditional" development in a couple of different aspects.

The main difference is that you can't really do local development anymore. This is because serverless services often cannot be run on your local machine, they only exist in the cloud. Some of the examples are [Amazon API Gateway](https://aws.amazon.com/api-gateway/), [Amazons SQS](https://aws.amazon.com/sqs/), [Amazon Cognito](https://aws.amazon.com/cognito/), and so on.

- development in cloud - no local development

- testing

E2E - https://dev.to/theburningmonk/why-you-should-use-temporary-stacks-when-you-do-serverless-2ai0

Developing and testing serverless applications locally can be a challenge. Even with tools like AWS Serverless Application Model (SAM) and the Serverless Framework, you often end up mocking your cloud resources, or resorting to tricks (like using pseudo-variables) to build ARNs and service endpoint URLs manually. While these workarounds may have the desired result, they also complicate our configuration files with (potentially brittle) user-constructed strings, which duplicates information already available to CloudFormation.

This is a common problem for me and other serverless developers I know. So I decided to come up with a solution.

Hi Steve,

I’m sort of with you on that. I really like developing applications locally because of the speed of the feedback loop. However, once you start wiring up different cloud services, local development can get tricky. I often build a number of mocks to support the remote calls, and then test my code using a test runner (as opposed to something like sls invoke local -f someFunction -p event.json). This obviously takes more time to set up, but I also end up with a much more solid application.

Integration testing an individual function from your local machine or a CI/CD system is also (somewhat) trivial if you generate the correct resource identifiers (SQS QueueUrl, for example) which is one of the main reason behind this plugin. However, once you have multiple functions working in concert, either as a choreographed workflow with queues/SNS Topic/DynamoDB streams/etc., or orchestrated as Step Functions, the local testing piece doesn’t really help. Having an observability tool (at least in my experience) has been the best way to understand what’s actually happening.

Thanks for the comment,
Jeremy
